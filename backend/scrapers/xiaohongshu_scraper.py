"""å°çº¢ä¹¦æ•°æ®æŠ“å–å™¨ - åŸºäº Spider_XHS API çˆ¬è™«ï¼ˆæ›¿ä»£ Playwright æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼‰"""
import asyncio
import time
import re
from typing import List, Dict, Any
from loguru import logger
from config import settings
from spider_xhs.apis.xhs_pc_apis import XHS_Apis
from spider_xhs.xhs_utils.data_util import handle_note_info


class XiaohongshuScraper:
    """å°çº¢ä¹¦ç¬”è®°æŠ“å–å™¨ï¼ˆAPI çˆ¬è™«ç‰ˆï¼‰"""
    
    def __init__(self):
        self.platform = "xiaohongshu"
        self.xhs_apis = XHS_Apis()
    
    @property
    def cookies_str(self) -> str:
        """è·å– cookie å­—ç¬¦ä¸²"""
        cookie = settings.xhs_cookies
        if not cookie:
            raise Exception("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® XHS_COOKIESï¼ˆä»æµè§ˆå™¨ F12 è·å–å°çº¢ä¹¦ç™»å½• cookieï¼‰")
        return cookie
    
    async def search(self, keyword: str, max_results: int = 10) -> List[Dict[str, Any]]:
        """æœç´¢ç¬”è®°å¹¶æå–åœ°ç‚¹ä¿¡æ¯
        
        Args:
            keyword: æœç´¢å…³é”®è¯ï¼Œå¦‚"æ­å·è¥¿æ¹–ä¸€æ—¥æ¸¸"
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
        
        Returns:
            åœ°ç‚¹ä¿¡æ¯åˆ—è¡¨
        
        Raises:
            Exception: å¦‚æœæœç´¢å¤±è´¥
        """
        logger.info(f"ğŸ” Spider_XHS æœç´¢: {keyword}, æœ€å¤š {max_results} æ¡")
        
        # 1. æœç´¢ç¬”è®°åˆ—è¡¨ï¼ˆåŒæ­¥è°ƒç”¨æ”¾åˆ°çº¿ç¨‹æ± ä¸­é¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
        loop = asyncio.get_event_loop()
        success, msg, notes = await loop.run_in_executor(
            None,
            lambda: self.xhs_apis.search_some_note(
                query=keyword,
                require_num=max_results,
                cookies_str=self.cookies_str,
                sort_type_choice=0,  # ç»¼åˆæ’åº
                note_type=2,  # ä»…å›¾æ–‡ç¬”è®°ï¼ˆæ—…è¡Œæ”»ç•¥é€šå¸¸æ˜¯å›¾æ–‡ï¼‰
            )
        )
        
        if not success:
            logger.error(f"æœç´¢å¤±è´¥: {msg}")
            raise Exception(f"å°çº¢ä¹¦æœç´¢å¤±è´¥: {msg}")
        
        # è¿‡æ»¤å‡ºç¬”è®°ç±»å‹çš„ç»“æœ
        notes = [n for n in notes if n.get('model_type') == 'note']
        logger.info(f"ğŸ“‹ æœç´¢åˆ° {len(notes)} ç¯‡ç¬”è®°")
        
        # 2. è·å–æ¯ä¸ªç¬”è®°çš„è¯¦ç»†ä¿¡æ¯
        results = []
        for note in notes[:max_results]:
            try:
                note_id = note.get('id', '')
                xsec_token = note.get('xsec_token', '')
                note_url = f"https://www.xiaohongshu.com/explore/{note_id}?xsec_token={xsec_token}&xsec_source=pc_search"
                
                # è·å–ç¬”è®°è¯¦æƒ…
                detail_success, detail_msg, detail_json = await loop.run_in_executor(
                    None,
                    lambda url=note_url: self.xhs_apis.get_note_info(url, self.cookies_str)
                )
                
                if detail_success and detail_json:
                    note_data = detail_json['data']['items'][0]
                    note_data['url'] = note_url
                    note_info = handle_note_info(note_data)
                    
                    # è½¬æ¢ä¸º DayTripPlanner æ ¼å¼
                    result = self._convert_to_place_info(note_info)
                    if result:
                        results.append(result)
                        logger.info(f"  âœ… {result['title'][:30]}...")
                else:
                    logger.warning(f"  âŒ è·å–ç¬”è®°è¯¦æƒ…å¤±è´¥: {detail_msg}")
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                await asyncio.sleep(0.5)
                
            except Exception as e:
                logger.warning(f"  âŒ å¤„ç†ç¬”è®°å¤±è´¥: {e}")
                continue
        
        logger.info(f"ğŸ“ å…±è·å– {len(results)} æ¡æœ‰æ•ˆç»“æœ")
        return results
    
    def _convert_to_place_info(self, note_info: dict) -> Dict[str, Any]:
        """å°†çˆ¬è™«è·å–çš„ç¬”è®°ä¿¡æ¯è½¬æ¢ä¸º DayTripPlanner çš„åœ°ç‚¹æ ¼å¼
        
        Args:
            note_info: handle_note_info å¤„ç†åçš„ç¬”è®°ä¿¡æ¯
        
        Returns:
            æ ¼å¼åŒ–çš„åœ°ç‚¹ä¿¡æ¯å­—å…¸
        """
        title = note_info.get('title', '')
        desc = note_info.get('desc', '')
        
        if not title:
            return None
        
        # ä»æ ‡é¢˜æå–åœ°ç‚¹åç§°
        place_name = self._extract_place_name(title)
        
        # çŒœæµ‹ç±»åˆ«
        category = self._guess_category(title + " " + desc)
        
        # è§£æäº’åŠ¨æ•°æ®
        likes = self._safe_int(note_info.get('liked_count', 0))
        collected = self._safe_int(note_info.get('collected_count', 0))
        comments = self._safe_int(note_info.get('comment_count', 0))
        
        return {
            "name": place_name,
            "title": title,
            "description": desc[:500] if desc else "",
            "likes": likes,
            "collected": collected,
            "comments": comments,
            "note_url": note_info.get('note_url', ''),
            "category": category,
            "source": "xiaohongshu",
            "tags": note_info.get('tags', []),
            "images": note_info.get('image_list', [])[:3],  # æœ€å¤šä¿ç•™3å¼ å›¾
            "author": note_info.get('nickname', ''),
            "upload_time": note_info.get('upload_time', ''),
        }
    
    def _safe_int(self, value) -> int:
        """å®‰å…¨è½¬æ¢ä¸ºæ•´æ•°"""
        if isinstance(value, int):
            return value
        if isinstance(value, str):
            text = value.strip()
            if not text:
                return 0
            try:
                if "ä¸‡" in text:
                    return int(float(text.replace("ä¸‡", "")) * 10000)
                elif "k" in text.lower():
                    return int(float(text.lower().replace("k", "")) * 1000)
                else:
                    return int(re.sub(r"[^\d]", "", text) or 0)
            except:
                return 0
        return 0
    
    def _guess_category(self, text: str) -> str:
        """æ ¹æ®æ–‡æœ¬çŒœæµ‹ç±»åˆ«"""
        food_keywords = ["ç¾é£Ÿ", "é¤å…", "å¥½åƒ", "åƒé¥­", "ç«é”…", "å’–å•¡", "ç”œå“", "å°åƒ", "é¢é¦†", "é¥­åº—", "çƒ§çƒ¤", "å¥¶èŒ¶"]
        attraction_keywords = ["æ™¯ç‚¹", "æ‰“å¡", "æ‹ç…§", "é£æ™¯", "å…¬å›­", "å¤é•‡", "åšç‰©é¦†", "å¯ºåº™", "æ¹–", "å±±", "å¤åŸ", "å¤œæ™¯"]
        shopping_keywords = ["è´­ç‰©", "å•†åœº", "å¸‚é›†", "ä¹°", "ç‰¹äº§", "æ­¥è¡Œè¡—"]
        
        for kw in food_keywords:
            if kw in text:
                return "ç¾é£Ÿ"
        for kw in attraction_keywords:
            if kw in text:
                return "æ™¯ç‚¹"
        for kw in shopping_keywords:
            if kw in text:
                return "è´­ç‰©"
        
        return "æ™¯ç‚¹"  # é»˜è®¤
    
    def _extract_place_name(self, title: str) -> str:
        """ä»æ ‡é¢˜æå–åœ°ç‚¹åç§°"""
        # ç®€å•å¤„ç†ï¼šå–|æˆ–ï½œå‰çš„éƒ¨åˆ†
        for sep in ["|", "ï½œ", "â€”", "-", "Â·"]:
            if sep in title:
                title = title.split(sep)[0].strip()
                break
        
        # ç§»é™¤å¸¸è§å‰ç¼€
        prefixes = ["æ¨è", "å¿…å»", "æ¢åº—", "æ‰“å¡"]
        for prefix in prefixes:
            title = title.replace(prefix, "")
        
        return title.strip()[:30]  # é™åˆ¶é•¿åº¦


# å…¨å±€å®ä¾‹
xiaohongshu_scraper = XiaohongshuScraper()
